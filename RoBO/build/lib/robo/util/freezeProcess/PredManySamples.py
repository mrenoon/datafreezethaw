# encoding=utf8
__author__ = "Tulio Paiva"
__email__ = "paivat@cs.uni-freiburg.de"

import numpy as np
from robo.util.freezeProcess.PredictiveHyper import PredictiveHyper
from robo.util.freezeProcess.PredictiveOld import PredictiveOld
from robo.util.freezeProcess.PredictiveNew import PredictiveNew
from robo.util.freezeProcess.LikIntegrate import LikIntegrate


class PredSamples(object):
	"""
	A class for controlling all different types of GPs, and doing predictions by integrating out
	the different samples of the GP hyperparameters
	
	Parameters
	----------
	samples: ndarray(number_samples, D)
			 All samples generated by the MCMC from LikIntegrate. Each sample contain samples 
			 for every GP hyperparameter
	x_train: ndarray(N, D)
			 The input training data ofor all GPs
	y_train: ndarray(T, N)
			 The target training data for all GPs
	x_test: ndarray(*, D)
			 The current test data of the GPs
	predHyper: boolean
			   Whether the posterior predictive over the hyperparameter is to be activated
	predOld: boolean
			   Whether the posterior predictive over the training curve of an old configuration is to be activated
	predNew: boolean
			   Whether the posterior predictive over the training curve of a new configuration is to be activated
	"""	
	def __init__(self,
				 samples,
				 x_train = None,
				 y_train = None,
				 x_test = None,
				 predHyper=True,
				 predOld=True,
				 predNew=True,
				 invChol=True,
				 samenoise=True):
		
		self.samples = samples
		self.x_train = x_train
		self.y_train = y_train
		self.x_test = x_test
		self.invChol = invChol
		self.samenoise = samenoise
		
		if predHyper:
			self.ph = PredictiveHyper(x_train, y_train, x_test, invChol=self.invChol, samenoise=self.samenoise)
		else:
			self.ph= None
		
		if predOld:
			self.po = PredictiveOld(x_train, y_train, x_test, samenoise=self.samenoise)
		else:
			self.po = None
		
		if predNew:
			self.pn = PredictiveNew(x_train, y_train, x_test, samenoise=self.samenoise)
		else:
			self.pn = None
		
		self.C_samples = np.zeros((samples.shape[0], self.x_train.shape[0], self.x_train.shape[0]))
		self.mu_samples = np.zeros((samples.shape[0], self.x_train.shape[0], 1))
		self.activated = False
			

	def pred_hyper(self, xprime=None):
		
		if xprime != None:
			self.x_test = xprime
		
		divby = self.samples.shape[0]
		
		mean_temp = np.zeros((self.samples.shape[0], xprime.shape[0]))
		std2_temp = np.zeros((self.samples.shape[0], xprime.shape[0]))
		
		for i in xrange(self.samples.shape[0]):
			self.ph.setGpHypers(self.samples[i])
			mean_one, std2_one, C, mu = self.ph.predict_asy(xprime)
			mean_temp[i, :] = mean_one.flatten()
			std2_temp[i, :] = std2_one.flatten()
			self.C_samples[i, ::] = C
			self.mu_samples[i, ::] = mu
		
		mean = np.mean(mean_temp, axis=0)
		std2 = np.mean((std2_temp**2 + mean_temp**2), axis=0)
		std2 -= mean**2
		
		self.activated = True
		
		
		return mean, std2
	
	def pred_hyper(self, xprime=None):
		"""
		Predicts mean and std2 for new configurations xprime. The prediction is averaged for
		all GP hyperparameter samples. They are integrated out.
		
		Parameters
		----------
		xprime: ndarray(*, D)
				the new configurations for which the mean and the std2 are being predicted
		
		Returns
		-------
		mean: ndarray(*,1)
			  predicted mean for every new configuration in xprime
		std2: ndarray(*,1)
			  predicted std2 for every new configuration in xprime
		divby: integer
			   number of GP hyperparameter samples which deliver acceptable results for mean
			   and std2. 
		"""
		if xprime != None:
			self.x_test = xprime
		
		samples_val = []
		C_valid = []
		mu_val = []
		means_val = []
		std2s_val = []
		
		divby = self.samples.shape[0]
		
		
		for i in xrange(self.samples.shape[0]):
			self.ph.setGpHypers(self.samples[i])
			pre = self.ph.predict_asy(xprime)
			#print 'pre: ', pre
			if pre!=None:
				mean_one, std2_one, C, mu = pre
				#print 'mean_one: ', mean_one
				means_val.append(mean_one.flatten())
				#print 'means_val: ', means_val
				std2s_val.append(std2_one.flatten())
				C_valid.append(C)
				mu_val.append(mu)
				samples_val.append(self.samples[i])
			else:
				divby -= 1 
				#print 'bad: ', divby
		
		mean_temp = np.zeros((divby, xprime.shape[0]))
		std2_temp = np.zeros((divby, xprime.shape[0]))
		
		if(divby < self.samples.shape[0]):
			self.C_samples = np.zeros((divby, self.C_samples.shape[1], self.C_samples.shape[2]))
			self.mu_samples = np.zeros((divby, self.mu_samples.shape[1], self.mu_samples.shape[2]))
			self.samples = np.zeros((divby, self.samples.shape[1]))
		
		
		for j in xrange(divby):
			mean_temp[j,:] = means_val[j]
			std2_temp[j,:] = std2s_val[j]
			self.C_samples[j, ::] = C_valid[j]
			self.mu_samples[j, ::] = mu_val[j]
			self.samples[j, ::] = samples_val[j]
		

		

		mean = np.mean(mean_temp, axis=0)
		std2 = np.mean(std2_temp, axis=0) + np.mean(mean_temp**2, axis=0)
		std2 -= mean**2
		
		self.activated = True
		self.asy_mean = mean
		
		return mean, std2, divby

		
	
	def pred_old(self, conf_nr, steps, fro=None):
		"""
		Here conf_nr is from 1 onwards. That's why we are using mu_n = mu[conf_nr - 1, 0] in the for-loop
		"""
		
		if self.activated:
			
			means_val = []
			std2s_val = []
			divby = self.samples.shape[0]
			
			yn = self.y_train[conf_nr -1]
			if fro == None:
				t = np.arange(1, yn.shape[0] +1)
				tprime = np.arange(yn.shape[0] +1, yn.shape[0] +1 +steps)
			else:
				t = np.arange(1, fro)
				tprime = np.arange(fro, fro + steps)				
			
	
			for i in xrange(self.samples.shape[0]):
				#print 'samples: ', self.samples
				self.po.setGpHypers(self.samples[i])
				
				mu = self.mu_samples[i, ::]
				mu_n = mu[conf_nr - 1, 0]
				
				C = self.C_samples[i, ::]
				Cnn = C[conf_nr - 1, conf_nr -1]
				
				
				pre = self.po.predict_new_point1(t, tprime, yn, mu_n, Cnn)

				if pre!= None:
					mean_one, std2_one = pre
					means_val.append(mean_one.flatten())
					std2s_val.append(std2_one.flatten())
				else:
					divby-=1
			
			mean_temp = np.zeros((divby, steps))
			std2_temp = np.zeros((divby, steps))
			
			for j in xrange(divby):
				mean_temp[j,:] = means_val[j]
				std2_temp[j,:] = std2s_val[j]

			mean = np.mean(mean_temp, axis=0)
			std2 = np.mean(std2_temp, axis=0) + np.mean(mean_temp**2, axis=0)
			std2 -= mean**2
	
			
			return mean, std2, divby
		
		else:
			raise Exception
		
	
	def pred_new(self, steps=13, xprime=None, y=None, asy=False):
		"""
		Params
		------
		asy: Whether the asymptotic has already been calculated or not.
		"""
		if xprime != None:
			self.x_test = xprime
		
		#Not redundant here. The  PredictiveHyper2 object is already created. In case kx has already been calculate
		#it's not going to be calculated a second time. 
		if asy==False:
			asy_mean, std2star, _ = self.pred_hyper2(xprime)
		else:
			asy_mean = self.asy_mean
		
		mean_temp = np.zeros((self.samples.shape[0], steps))
		std2_temp = np.zeros((self.samples.shape[0], steps))
	
		for i in xrange(self.samples.shape[0]):
			self.pn.setGpHypers(self.samples[i])
				
			mean_one, std2_one = self.pn.predict_new_point2(steps, asy_mean[1], y)
			mean_temp[i, :] = mean_one.flatten()
			std2_temp[i, :] = std2_one.flatten()
			
		mean = np.mean(mean_temp, axis=0)
		std2 = np.mean(std2_temp, axis=0) + np.mean(mean_temp**2, axis=0)
		std2 -= mean**2
		return mean, std2
		
	

if __name__ == '__main__':
		
	y1 = np.random.rand(3,1)
	y2 = np.random.rand(2,1)
	y3 = np.random.rand(4,1)
	y = np.array([y1,y2,y3], dtype=object)
	
	x = np.array([[2, 3, 3.2, 1.5, 2.3, 2.7, 3.6], [4, 5, 5.1, 5.2, 5.7, 5.72, 5.8], [5, 8, 8.1, 8.32, 8.4, 8.46, 8.53]])/10.
	
	#likint = LikIntegrate()
	#samples = likint.create_configs(x,y)
	
	#ps = PredSamples(samples, x, y)

	#xTest = np.array([[10., 10.3, 10.4, 10.55, 10.73, 11.2, 11.4], [9.1, 9.15, 9.18, 9.24, 9.37, 9.42, 9.58]])/10.
	
	#mean, std2, divby = ps.pred_hyper2(xTest)
	
	#print 'mean: ', mean
	#print 'std2: ', std2
	#print 'div_by: ', divby
